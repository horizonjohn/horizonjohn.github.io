---
---


@article{jiang2024haifit,
  title={HAIFIT: Human-to-AI Fashion Image Translation},
  author={Jiang, Jianan and Li, Xinglin and Yu, Weiren and Wu, Di},
  journal={arXiv preprint arXiv:2403.08651},
  year={2024},
  abstract={We first treated input sketches as sequences to maintain consistency from forward and reverse directions, inspired by human perception.},
  pdf={https://arxiv.org/pdf/2403.08651},
  preview={HAIFIT.png},
  code={https://github.com/ExponentiAI/HAIFIT},
  abbr={Preprint}
}

@inproceedings{jiang2025arnet,
  title={ARNet: Self-Supervised FG-SBIR with Unified Sample Feature Alignment and Multi-Scale Token Recycling},
  author={Jiang, Jianan and Tang, Han and Jiang, Zhilin and Yu, Weiren and Wu, Di},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2025},
  selected={true},
  abstract={We achieved better feature alignment and representation through a straightforward framework design by optimizing features for both intra- and inter-samples, and recycling discarded patch tokens in ViT-based backbones via contrastive learning.},
  pdf={https://arxiv.org/pdf/2406.11551},
  preview={ARNet.png},
  doi={10.1609/aaai.v39i4.32417},
  code={https://github.com/ExponentiAI/ARNet},
  abbr={AAAI'25}
}

@article{lu2024fpga,
  title={FPGA Adaptive Neural Network Quantization for Adversarial Image Attack Defense},
  author={Lu*, Yufeng and Shi*, Xiaokang and Jiang, Jianan and Deng, Hanhui and Wang, Yanwen and Lu, Jiwu and Wu, Di},
  journal={IEEE Transactions on Industrial Informatics},
  year={2024},
  publisher={IEEE},
  abstract={We achieved image adversarial attack and defense on the FPGA platform while ensuring model performance.},
  preview={FPGA.png},
  doi={10.1109/TII.2024.3438284},
  abbr={IEEE T-II'24}
}

@article{jiang2024haigen,
  title={HAIGEN: Towards Human-AI Collaboration for Facilitating Creativity and Style Generation in Fashion Design},
  author={Jiang, Jianan and Wu, Di and Deng, Hanhui and Long, Yidan and Tang, Wenyi and Li, Xiang and Liu, Can and Jin, Zhanpeng and Zhang, Wenlei and Qi, Tangquan},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={8},
  number={3},
  pages={1--27},
  year={2024},
  publisher={ACM New York, NY, USA},
  selected={true},
  abstract={We introduced a system to facilitate the entire design process with a Human-AI collaborative framework, harnessing the powerful capabilities of cloud large models and the convenience of local small models through well-designed methodologies for each modules.},
  pdf={https://arxiv.org/pdf/2408.00855},
  preview={HAIGEN.png},
  doi={10.1145/3678518},
  code={https://github.com/ExponentiAI/HAIGEN},
  video={https://youtu.be/ijIJdaOUrlo},
  abbr={Ubicomp'24}
}

@article{wu2024stylewe,
  title={StyleWe: Towards Style Fusion in Generative Fashion Design with Efficient Federated AI},
  author={Wu*, Di and Wu*, Mingzhu and Li*, Yeye and Jiang, Jianan and Li, Xinglin and Deng, Hanhui and Liu, Can and Li, Yi},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={8},
  number={CSCW2},
  pages={1--31},
  year={2024},
  publisher={ACM New York, NY, USA},
  abstract={We introduce StyleWe, which employs a lightweight GAN with model compression and a federated learning algorithm to generate unexpected sketch styles by facilitating sketch styles fusion among multiple designers while ensuring privacy protection.},
  preview={StyleWe.png},
  doi={10.1145/3687054},
  code={https://github.com/ExponentiAI/StyleWe},
  abbr={CSCW'24},
  award={One of 5 Awardees, **1%**.},
  award_name={Best Paper Award}
}

@article{deng2024crossgai,
  title={CrossGAI: A Cross-Device Generative AI Framework for Collaborative Fashion Design},
  author={Deng*, Hanhui and Jiang*, Jianan and Yu, Zhiwang and Ouyang, Jinhui and Wu, Di},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={8},
  number={1},
  pages={1--27},
  year={2024},
  publisher={ACM New York, NY, USA},
  selected={true},
  abstract={We introduce CrossGAI, which employs multiple AI modules and the Lyapunov algorithm with a DNN actor to dynamically optimize network bandwidth across different clients, supporting collaboration among multiple designers on various devices across different regions.},
  preview={CrossGAI.png},
  doi={10.1145/3643542},
  video={https://www.youtube.com/watch?v=UoJa98hTgEM},
  abbr={Ubicomp'24}
}

@inproceedings{wu2023styleme,
  title={Styleme: Towards Intelligent Fashion Generation with Designer Style},
  author={Wu*, Di and Yu*, Zhiwang and Ma*, Nan and Jiang, Jianan and Wang, Yuetian and Zhou, Guixiang and Deng, Hanhui and Li, Yi},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2023},
  abstract={We introduce StyleMe, which employs Grad-CAM and AdaLIN to guide the generation of sketches, preserving the designer's unique style in sketches. Additionally, it utilizes a two-stage generation network, combining AE and GAN, to color the generated sketches with a personalized style.},
  preview={StyleMe.png},
  doi={10.1145/3544548.3581377},
  code={https://github.com/ExponentiAI/StyleMe},
  abbr={CHI'23}
}
